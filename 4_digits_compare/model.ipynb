{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project requirements: Compare if two digits are the same\n",
    "#### Project goal: accuracy on test > 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import random\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def reset_graph():\n",
    "    tf.reset_default_graph()\n",
    "    seed = random.randint(1, 500)\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(X):\n",
    "    return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reshape_data(X_train)\n",
    "X_test = reshape_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(x):\n",
    "    if x != 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vscale = np.vectorize(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vscale(X_train)\n",
    "X_test = vscale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "X_batch, y_batch = generate_batch(X_train, y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2, 784), dtype('int64'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape, X_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First three rows (digits) are the same (\"ones\") but last two are diffrent (\"zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_init = tf.keras.initializers.VarianceScaling()\n",
    "n_inputs = 28 * 28 # zbi√≥r MNIST\n",
    "learning_rate = 0.01\n",
    "momentum = 0.92\n",
    "n_epochs = 151\n",
    "batch_size = 1500\n",
    "X_test, y_test = generate_batch(X_test, y_test, batch_size=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100, name=None, activation=tf.nn.elu, initializer=he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-1395d2fdba22>:6: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/thatone/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "*Test* epoch: 0 accuracy: 0.4991 loss: 0.6936644\n",
      "*Test* epoch: 10 accuracy: 0.7722 loss: 0.50140333\n",
      "*Test* epoch: 20 accuracy: 0.8468 loss: 0.36936772\n",
      "*Test* epoch: 30 accuracy: 0.8914 loss: 0.28948665\n",
      "*Test* epoch: 40 accuracy: 0.9113 loss: 0.24010034\n",
      "*Test* epoch: 50 accuracy: 0.924 loss: 0.1895744\n",
      "*Test* epoch: 60 accuracy: 0.9373 loss: 0.17167248\n",
      "*Test* epoch: 70 accuracy: 0.9428 loss: 0.12680458\n",
      "*Test* epoch: 80 accuracy: 0.9492 loss: 0.11247782\n",
      "*Test* epoch: 90 accuracy: 0.9535 loss: 0.09718114\n",
      "*Test* epoch: 100 accuracy: 0.9563 loss: 0.115926564\n",
      "*Test* epoch: 110 accuracy: 0.96 loss: 0.10598052\n",
      "*Test* epoch: 120 accuracy: 0.9589 loss: 0.08233658\n",
      "*Test* epoch: 130 accuracy: 0.9628 loss: 0.08710274\n",
      "*Test* epoch: 140 accuracy: 0.9638 loss: 0.08637983\n",
      "*Test* epoch: 150 accuracy: 0.9664 loss: 0.068575285\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name=\"X\")\n",
    "    X1, X2 = tf.unstack(X, axis=1)\n",
    "    y = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "    dnn1 = dnn(X1, name=\"DNN_A\")\n",
    "    dnn2 = dnn(X2, name=\"DNN_B\")\n",
    "    dnn_outputs = tf.concat([dnn1, dnn2], axis = 1)\n",
    "    hidden = tf.layers.dense(dnn_outputs, units = 10, activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "    logits = tf.layers.dense(hidden, units = 1, kernel_initializer=he_init)\n",
    "    # y_proba = tf.nn.sigmoid(logits)\n",
    "    y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32) # Equal to p_proba >= 0.5\n",
    "    y_as_float = tf.cast(y, tf.float32)\n",
    "    xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy) \n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    y_pred_correct = tf.equal(y_pred, y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(X_train) // batch_size):\n",
    "            X_batch, y_batch = generate_batch(X_train, y_train, batch_size)\n",
    "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print('*Test*', 'epoch:', epoch, 'accuracy:', acc_test, 'loss:', loss_val)\n",
    "    save_path = saver.save(sess, \"./model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy: ~96.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
