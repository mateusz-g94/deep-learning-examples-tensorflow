{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project goal: accuracy > 99.0% on independent test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow v > 2 but using compat.v1 (transition code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import random\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os\n",
    "from scipy.stats import reciprocal\n",
    "from datetime import datetime\n",
    "from net import DNNMiniBatchEarlyStoppingTF\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data(X):\n",
    "    return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_re, X_test_re = reshape_data(X_train), reshape_data(X_test)\n",
    "X_train_re, X_test_re = X_train_re.astype(float), X_test_re.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wizualizacja przykladowych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilosc przykladow uczacych: 60000\n",
      "Ilosc przykladow testowych: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Ilosc przykladow uczacych:', len(X_train))\n",
    "print('Ilosc przykladow testowych:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(X, y, n = None):\n",
    "    if not n:\n",
    "        n = random.randint(0, len(X))\n",
    "    digit, label = X[n], y[n]\n",
    "    plt.imshow(digit, cmap = matplotlib.cm.binary, interpolation = 'nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Label:\" + str(label))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale(X):\n",
    "    \n",
    "#     def scale(x):\n",
    "#         if x != 0:\n",
    "#             return 1\n",
    "#         else:\n",
    "#             return 0\n",
    "        \n",
    "#     func = np.vectorize(scale)\n",
    "    \n",
    "#     return func(X)\n",
    "def scale(X):\n",
    "    \n",
    "    def scale(x):\n",
    "        return x / 255.0\n",
    "        \n",
    "    func = np.vectorize(scale)\n",
    "    \n",
    "    return func(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = scale(X_train), scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset grafu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def reset_graph():\n",
    "    tf.reset_default_graph()\n",
    "    seed = random.randint(1, 500)\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNConv(DNNMiniBatchEarlyStoppingTF):\n",
    "    \n",
    "    def net(self, X, y, seed = 77, learning_rate = 0.01):\n",
    "        \"\"\"\n",
    "        Model - stworzenie grafu obliczen.\n",
    "        \"\"\"\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        if self.reshape_input:\n",
    "            X = tf.reshape(X, shape=[-1, int(math.sqrt(n_inputs)), int(math.sqrt(n_inputs)), 1])\n",
    "        he_init = tf.keras.initializers.VarianceScaling()\n",
    "        training = tf.placeholder_with_default(False, shape=(), name='train_f')\n",
    "        with tf.name_scope(\"DNN_Model\"):\n",
    "            with tf.name_scope(\"net_conv\"):\n",
    "                X = tf.layers.conv2d(X, filters = 32, kernel_size = 3,\n",
    "                         strides = 1, padding = \"SAME\", activation = tf.nn.relu, name = \"conv1\")\n",
    "                X = tf.layers.conv2d(X, filters = 64, kernel_size = 3,\n",
    "                         strides = 1, padding = \"SAME\", activation = tf.nn.relu, name = \"conv2\")\n",
    "                X = tf.nn.max_pool(X, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"VALID\")\n",
    "                X = tf.reshape(X, shape=[-1, 64 * 14 * 14])\n",
    "                X = tf.layers.dropout(X, 0.2, training = training)\n",
    "            with tf.name_scope(\"net_fully_connected\"):\n",
    "                for layer, i in zip(self.layers[:-1], range(len(self.layers[:-1]))):\n",
    "                    X = tf.layers.dense(X, layer, name = \"hidden\" + str(i), kernel_initializer = he_init)\n",
    "                    X = tf.layers.dropout(X, self.dropout_rate, training = training)\n",
    "                    #X = tf.layers.batch_normalization(X, training = training, momentum=0.9)\n",
    "                    X = tf.nn.relu(X)\n",
    "                logits = tf.layers.dense(X, self.layers[-1], kernel_initializer = he_init, name = 'logits') # Bez softmax bo jest zaimplementowana juz w loss function  \n",
    "                #logits = tf.layers.batch_normalization(logits, training = training, momentum=0.9)\n",
    "            with tf.name_scope(\"loss\"):\n",
    "                xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "                loss = tf.reduce_mean(xentropy, name = \"loss\")\n",
    "                loss_summary = tf.summary.scalar('loss', loss)\n",
    "            with tf.name_scope(\"learning\"):\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate, momentum = 0.9, use_nesterov = True)\n",
    "                grads_and_vars = optimizer.compute_gradients(loss)\n",
    "                capped_gvs = [(tf.clip_by_value(grad, -self.threshold, self.threshold), var)\n",
    "                              for grad, var in grads_and_vars]\n",
    "                training_op = optimizer.apply_gradients(capped_gvs)\n",
    "#                 optimizer = tf.train.AdamOptimizer()\n",
    "#                 training_op = optimizer.minimize(loss)\n",
    "            with tf.name_scope(\"eval\"):\n",
    "                correct = tf.nn.in_top_k(logits, y, 1)\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "                accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "            with tf.name_scope(\"init\"):\n",
    "                init = tf.global_variables_initializer()\n",
    "            with tf.name_scope(\"save\"):\n",
    "                saver = tf.train.Saver(max_to_keep = 1000000)                        \n",
    "        return training_op, loss, loss_summary, accuracy, accuracy_summary, init, saver, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {}\n",
    "# params['n_epochs'] = 25 + 1\n",
    "# params['layers'] = [256, 128, 10] # Fully conected layers\n",
    "# params['n_iterations'] = 5\n",
    "# params['dropout_rate'] = 0.25 # In fully cconnected layers\n",
    "# params['learning_rate_init'] = 0.002\n",
    "# params['learning_rate_range'] = (0.001, 0.01)\n",
    "# params['threshold'] = 1\n",
    "# params['batch_size'] = 50\n",
    "# params['reshape_input'] = True # If conv then initial reshape from dense\n",
    "# params['pr_epochs'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params\n",
    "# 1) 99.15 \n",
    "params = {}\n",
    "params['n_epochs'] = 17 + 1\n",
    "params['layers'] = [256, 128, 10] # Fully conected layers\n",
    "params['n_iterations'] = 1\n",
    "params['dropout_rate'] = 0.30 # In fully cconnected layers\n",
    "params['learning_rate_init'] = 0.0013\n",
    "params['learning_rate_range'] = (0.001, 0.01)\n",
    "params['threshold'] = 1\n",
    "params['batch_size'] = 50\n",
    "params['reshape_input'] = True # If conv then initial reshape from dense\n",
    "params['pr_epochs'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNNConv(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przebieg: 1\n",
      "    Logdir: ./log/log--20201113092925/\n",
      "    Learning rate: 0.0013\n",
      "        Epoka: 1 \tLoss: 0.046617277 \tAccuracy: 0.9858\n",
      "        Epoka: 2 \tLoss: 0.04097281 \tAccuracy: 0.9872\n",
      "        Epoka: 3 \tLoss: 0.03651904 \tAccuracy: 0.9883\n",
      "        Epoka: 4 \tLoss: 0.040917244 \tAccuracy: 0.9875\n",
      "        Epoka: 5 \tLoss: 0.037650716 \tAccuracy: 0.9887\n",
      "        Epoka: 6 \tLoss: 0.03688749 \tAccuracy: 0.9893\n",
      "        Epoka: 7 \tLoss: 0.03310396 \tAccuracy: 0.99\n",
      "        Epoka: 8 \tLoss: 0.030036932 \tAccuracy: 0.9908\n",
      "        Epoka: 9 \tLoss: 0.03422913 \tAccuracy: 0.9896\n",
      "        Epoka: 10 \tLoss: 0.033602893 \tAccuracy: 0.9901\n",
      "        Epoka: 11 \tLoss: 0.033648785 \tAccuracy: 0.9915\n",
      "        Epoka: 12 \tLoss: 0.030919291 \tAccuracy: 0.9908\n",
      "        Epoka: 13 \tLoss: 0.038302574 \tAccuracy: 0.9907\n",
      "        Epoka: 14 \tLoss: 0.035127968 \tAccuracy: 0.9909\n",
      "        Epoka: 15 \tLoss: 0.04254543 \tAccuracy: 0.9898\n",
      "        Epoka: 16 \tLoss: 0.03592514 \tAccuracy: 0.9905\n",
      "        Epoka: 17 \tLoss: 0.03333552 \tAccuracy: 0.9917\n",
      "    Final iteration accuracy: 0.9917\n",
      "Final accuracy: 0.9917 Learning rate: 0.0013\n",
      "CPU times: user 3h 55min 11s, sys: 13min 25s, total: 4h 8min 36s\n",
      "Wall time: 1h 32min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "model.train(X_train = X_train_re, y_train = y_train, X_test = X_test_re, y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(X, y, pred, n = None):\n",
    "    if not n:\n",
    "        n = random.randint(0, len(X))\n",
    "    digit, label, pred = X[n], y[n], pred[n]\n",
    "    plt.imshow(digit, cmap = matplotlib.cm.binary, interpolation = 'nearest')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Label:\" + str(label) + \" Pred:\" + str(pred))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(X = X_test, y = y_test, pred = pred, n = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projec goal has been archieved (accuracy: ~ 99.2 %)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
